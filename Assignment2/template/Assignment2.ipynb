{"cells":[{"cell_type":"markdown","metadata":{"id":"LS7T20gWaEkg"},"source":["# Machine Vision - Assignment 2: Gradient Descent and Neural Networks in PyTorch\n","\n","---\n","\n","Prof. Dr. Markus Enzweiler, Esslingen University of Applied Sciences\n","\n","markus.enzweiler@hs-esslingen.de\n","\n","---\n","\n","### This is the second assignment for the \"Machine Vision\" lecture.\n","It covers:\n","* polynomial regression using gradient descent\n","* getting started with [PyTorch](https://pytorch.org)\n","* training multilayer perceptrons for traffic sign recognition\n","* working with public benchmark datasets ([German Traffic Sign Recognition Benchmark](https://benchmark.ini.rub.de/gtsrb_news.html))\n","\n","**Make sure that \"GPU\" is selected in Runtime -> Change runtime type**\n","\n","To successfully complete this assignment, it is assumed that you already have some experience in Python and numpy. You can either use [Google Colab](https://colab.research.google.com/) for free with a private (dedicated) Google account (recommended) or a local Jupyter installation.\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"bu0CrJ5N4ZuQ"},"source":["## Exercise 1 - PyTorch Tutorial (10 points)\n"]},{"cell_type":"markdown","metadata":{"id":"APZRY0-vEeC4"},"source":["### Introduction to PyTorch\n","\n","Work through the [\"Introduction to PyTorch\" tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) consisting of nine topics:\n","\n","*   Learn the Basics\n","*   Quickstart\n","*   Tensors\n","*   Datasets & DataLoaders\n","*   Transforms\n","*   Build Model\n","*   Autograd\n","*   Optimization\n","*   Save & Load Model\n","\n","You can run each part in Colab and inspect / modify the code and data. There are certainly some details that you do not yet understand. Don't let that stop you, but try to get a good overall view on working with PyTorch.\n","\n","**Please answer the questions below (directly in the notebook):**"]},{"cell_type":"markdown","metadata":{"id":"8mblBzbeFPfe"},"source":["### Question 1 (3 points)\n","\n"," Why does PyTorch have a dedicated tensor data structure (`torch.tensor`) and does not use NumPy multidimensional arrays exclusively?"]},{"cell_type":"markdown","metadata":{"id":"gdhJB1ZpGblX"},"source":["### Your Answer:\n","Tensors can run on GPU or other hardware accelarators, which NumPy arrays can not\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Mb0v9yIfGyrK"},"source":["### Question 2 (4 points)\n","\n"," In the [\"Build Model\"](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) section of the tutorial, there is a definition of a neural network, as follows:\n","\n","\n","```\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","```\n","\n","Explain the different parameters of the `nn.Linear()` layers. How are the numeric values, e.g. `28*28`, `512`, `10`, determined?  "]},{"cell_type":"markdown","metadata":{"id":"yJa-1kg4HXR5"},"source":["### Your Answer:\n","\n","28*28 = Image Size of the dataset - so from each pixel one input\n","\n","10 = output of the neural network, dataset has 10 labels. So for each label we have 1 output\n","\n","512 = choose of hidden layers. Can be determined by the user. Its common to use numbers by the power of 2. You can test with which number the model performs best\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bj6XE_JDIEBu"},"source":["### Question 3 (3 points)\n","\n"," In the [\"Optimization\"](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html) section of the tutorial, an example of a training loop is given:\n","\n"," ```\n","def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"," ```\n","\n"," Explain the effect of the function calls `optimizer.zero_grad()` and `optimizer.step()`."]},{"cell_type":"markdown","metadata":{"id":"5kWoiHofIfXd"},"source":["### Your Answer:\n","\n","optimizer.zero_grad() = reset the gradients, so we have no doulbe counting\n","\n","optimizer.step() = adjust the parameters by the collected gradients\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RH3vu3HiqaZS"},"source":["## Preparations and Imports\n"]},{"cell_type":"markdown","metadata":{"id":"XJOOn6oO8X3C"},"source":["### Package Path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPQaSW4f8aLt"},"outputs":[],"source":["# Package Path (this needs to be adapted)\n","packagePath = \"./\" # local\n","if 'google.colab' in str(get_ipython()):\n","  packagePath = \"/content/drive/My Drive/MachineVis2/template\"   # Colab"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Qi-nBr90uw-N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFz0s31SxNyP"},"source":["### Import important libraries (you should probably start with these lines all the time ...)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPcN62DgZ6Gg"},"outputs":[],"source":["# os, glob, time, logging\n","import os, glob, time, logging\n","\n","# NumPy\n","import numpy as np\n","\n","# OpenCV\n","import cv2\n","\n","# Matplotlib\n","import matplotlib.pyplot as plt\n","# make sure we show all plots directly below each cell\n","%matplotlib inline\n","\n","# PyTorch\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","# Some Colab specific packages\n","if 'google.colab' in str(get_ipython()):\n","  # image display\n","  from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"ANRNsyDPTm9x"},"source":["\n","### Some helper functions that we will need"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQ5AIQr1TsHU"},"outputs":[],"source":["def my_imshow(image, windowTitle=None, size=20, depth=3):\n","  '''\n","  Displays an image and differentiates between Google Colab and a local Python installation.\n","\n","  Args:\n","    image: The image to be displayed\n","\n","  Returns:\n","    -\n","  '''\n","\n","  if 'google.colab' in str(get_ipython()):\n","    print(windowTitle)\n","    cv2_imshow(image)\n","  else:\n","    if (size):\n","      (h, w) = image.shape[:2]\n","      aspectRatio = float(h)/w\n","      figsize=(size, size * aspectRatio)\n","      plt.figure(figsize=figsize)\n","\n","    if (windowTitle):\n","      plt.title(windowTitle)\n","\n","    if (depth == 1):\n","      plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n","    elif (depth == 3):\n","      plt.imshow(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n","    else:\n","      plt.imshow(image)\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ybKcetvDlt-o"},"source":["### In Google Colab only:\n","Mount the Google Drive associated with your Google account. You will have to click the authorization link and enter the obtained authorization code here in Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88rhI7gsltLi"},"outputs":[],"source":["# Mount Google Drive\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"LRE7wONf8ez8"},"source":["### PyTorch Trainer and Test Class\n","\n","In the project package, I have provided a Python file `torchHelpers.py` that contains two classes `Trainer` and `Tester`. These classes contain the neural network training loop and test code, similar to what you have already seen in the tutorial.\n","\n","The classes can be used as follows (see the documentation of the individual classes):\n","\n","```\n","# Train a neural network model\n","# create a trainer\n","trainer = Trainer(model, lossFunction, optimizer, device, logLevel=logging.INFO)\n","# train the model\n","trainer.train(trainLoader, valLoader, numberOfEpochs)\n","\n","# Test a neural network model\n","# create a tester\n","tester = Tester(model, device, logLevel=logging.INFO)\n","# test the model\n","tester.test(testLoader)\n","```\n","\n","Error and accuracy metrics are available after training / testing via `trainer.metrics` and `tester.metrics`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzeMhjWs9v-5"},"outputs":[],"source":["import sys\n","sys.path.append(packagePath)\n","print(\"If the import does not work, most likely your 'packagePath' is not set correctly!\")\n","print(f'packagePath: {packagePath}')\n","\n","from torchHelpers import Trainer, Tester\n","\n","help(Trainer)"]},{"cell_type":"markdown","metadata":{"id":"dlXyYMTNVS8t"},"source":["## Exercise 2 - Polynomial regression (10 points)\n","\n","This exercise involves fitting a polynomial model to given data using gradient descent. It is similar to the ```linear_regression``` example from [https://github.com/menzHSE/cv-ml-lecture-notebooks](https://github.com/menzHSE/cv-ml-lecture-notebooks) that we have discussed in the lecture, but with a polynomial model instead of the linear model.\n","\n","The polynomial model is given by:\n","$$\n","y = f(x) = a \\cdot x^3 + b \\cdot x^2 + c \\cdot x + d\n","$$\n","\n","Your task is to estimate $a$, $b$, $c$ and $d$ using gradient descent using mean squared error loss between the predictions $\\hat{y_i}$ of our model and true values $y_i$:\n","$$\n","L(a, b, c, d) \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2 = \\frac{1}{N} \\sum_{i=1}^{N} \\left(y_i - (a \\cdot x_i^3 + b \\cdot x_i^2 + c \\cdot x_i + d)\\right)^2\n","$$\n","\n","**Tasks**\n","\n","* Derive the gradient descent update rules to estimate $a$, $b$, $c$, and $d$\n","* Implement gradient descent to estimate $a$, $b$, $c$, and $d$ using your derived update rules\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gvkaV2zLVS8t"},"source":["### Load and visualize the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNqNfsWxVS8t"},"outputs":[],"source":["data_path = os.path.join(packagePath, \"data\", \"poly.csv\")\n","\n","# load data from csv\n","data = np.loadtxt(data_path, delimiter=\",\")\n","X = torch.Tensor(data[:, 0])\n","Y = torch.Tensor(data[:, 1])\n","# Visualize\n","plt.scatter(X, Y, alpha=0.5)\n","plt.title(\"Scatter plot of given data\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9QvwvwuKVS8t"},"source":["### Initialize parameters\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWqYxubqVS8t"},"outputs":[],"source":["a = torch.randn(1, dtype=torch.float32)\n","b = torch.randn(1, dtype=torch.float32)\n","c = torch.randn(1, dtype=torch.float32)\n","d = torch.randn(1, dtype=torch.float32)\n","\n","print(f\"Initial params : {a,b,c,d}\")"]},{"cell_type":"markdown","metadata":{"id":"JQUHrbPtVS8u"},"source":["### Estimate $a$, $b$, $c$, $d$ using gradient descent\n","\n","Use the following hyperparameters:\n","* 100000 iterations of gradient descent\n","* learning rate 1e-5"]},{"cell_type":"code","source":["def poly_model(a, b, c, d, x):\n","  return a * x**3 + b * x**2 + c * x + d\n","def loss_msl(y_pred, y):\n","  return torch.mean(torch.square(y-y_pred))\n","def loss_a(x,y,a,b,c,d):\n","  return torch.mean(-2 * (y - poly_model(a,b,c,d,x))*x**3)\n","def loss_b(x,y,a,b,c,d):\n","  return torch.mean(-2 * (y - poly_model(a,b,c,d,x))*x**2)\n","def loss_c(x,y,a,b,c,d):\n","  return torch.mean(-2 * (y - poly_model(a,b,c,d,x))*x)\n","def loss_d(x,y,a,b,c,d):\n","  return torch.mean(-2 * (y - poly_model(a,b,c,d,x)))\n","\n","\n","#Hyperparameters\n","\n","num_iteration = 10000\n","learning_rate = 1e-5\n","\n","for iteration in range (num_iteration):\n","  y_pred = poly_model(a,b,c,d,X)\n","\n","  loss = loss_msl(y_pred, Y)\n","\n","  grad_a = loss_a(X,Y,a,b,c,d)\n","  grad_b = loss_b(X,Y,a,b,c,d)\n","  grad_c = loss_c(X,Y,a,b,c,d)\n","  grad_d = loss_d(X,Y,a,b,c,d)\n","\n","  with torch.no_grad():\n","    a -= learning_rate * grad_a\n","    b -= learning_rate * grad_b\n","    c -= learning_rate * grad_c\n","    d -= learning_rate * grad_d\n","\n","  if iteration % 500 == 0 or iteration == 0:\n","    print(f\"Iteration {iteration} | Loss {loss.item()} | a {a.item()} | b{b.item()} | c {c.item()} | d {d.item()}\")\n","\n","print(f\"Final| a {a.item()} | b{b.item()} | c {c.item()} | d {d.item()}\")"],"metadata":{"id":"E3hkLw3ra037"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xUUfEf6JVS8u"},"source":["### Visualize the polynomial fit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBTUTVcpVS8u"},"outputs":[],"source":["# Visualize\n","plt.scatter(X, Y, alpha=0.5)\n","plt.title(\"Scatter plot of fitted polynomial\")\n","\n","# Plot the recovered line\n","Y_model = poly_model(a, b, c, d, X)\n","plt.plot(X.tolist(), Y_model.tolist(), color=\"red\")\n","\n","plt.legend([\"data\", f\"f(x)\"])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_IxxAKTfxxiU"},"source":["## Exercise 3 - Traffic Sign Classification using Multilayer Perceptrons in PyTorch (10 points)\n","\n","In this exercise you will train a multilayer perception neural network using PyTorch on the [German Traffic Sign Recognition Benchmark](https://benchmark.ini.rub.de/gtsrb_news.html) dataset. There will be no previous feature transform, i.e. the raw pixel values are the input to the neural network."]},{"cell_type":"markdown","metadata":{"id":"ouyODhArcfUL"},"source":["### Automatically select the best available device (**PROVIDED**)\n","\n","**In Colab: Make sure that \"GPU\" is selected in Runtime -> Change runtime type**\n","\n","You should have a GPU device available, e.g.:\n","\n","```\n","Using device: cuda\n","Tesla T4\n","```\n","\n","We will transfer our model and data to this device later on in the Assignment. PyTorch takes care of all the particular device handling automatically, i.e. we will not have to explicitly deal with CUDA / MPS."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNBnGSlxrN4Q"},"outputs":[],"source":["# Check the devices that we have available and prefer CUDA over MPS and CPU\n","def autoselectDevice(verbose=1):\n","\n","    # default: CPU\n","    device = torch.device('cpu')\n","\n","    if torch.cuda.is_available():\n","        # CUDA\n","        device = torch.device('cuda')\n","    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n","        # MPS (acceleration on Apple M-series SoC)\n","        device = torch.device('mps')\n","\n","    if verbose:\n","        print('Using device:', device)\n","\n","    # Additional Info when using cuda\n","    if verbose and device.type == 'cuda':\n","        print(torch.cuda.get_device_name(0))\n","\n","    return device\n","\n","# We transfer our model and data later to this device. If this is a GPU\n","# PyTorch will take care of everything automatically.\n","device = autoselectDevice(verbose=1)\n"]},{"cell_type":"markdown","metadata":{"id":"JFzeGgygOeX8"},"source":["### Getting familiar with the GTSRB dataset (**PROVIDED**)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXZ4tzXccZB9"},"outputs":[],"source":["# GTSRB is available as standard dataset in PyTorch. Nice :)\n","\n","# Data is loaded and processed in batches of 'batchSize' images\n","batchSize = 24\n","\n","# We can add a chain of transforms that is applied to the original data, e.g.\n","#    resize all images to the same dimensions, e.g. 64x64 pixels\n","#    convert (batch of) images to a tensor\n","#    normalize pixel values (to 0-1)\n","\n","transform = transforms.Compose(\n","    [transforms.Resize((64, 64)), # resize to 64x64 pixels\n","     transforms.ToTensor()        # convert to tensor. This will also normalize pixels to 0-1\n","     ])\n","\n","# We construct several DataLoaders that take care of loading, storing, caching, pre-fetching the dataset.\n","# We will have one DataLoader for training, validation and test data.\n","\n","# Training data\n","trainSet = torchvision.datasets.GTSRB(root='./data', split='train',\n","                                      download=True, transform=transform)\n","trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize,\n","                                          shuffle=True, pin_memory=True, num_workers=2)\n","numTrainSamples = len(trainSet)\n","\n","# Validation and test data\n","# GTSRB only provides a single test set. To create a validation and test set,\n","# we split the original GTSRB test set into two parts. The validation set is\n","# used to tune performance during training. The test set is only used AFTER\n","# training to evaluation the final performance.\n","\n","gtsrbTestSet = torchvision.datasets.GTSRB(root='./data', split='test',\n","                                          download=True, transform=transform)\n","\n","# Split the original GTSRB test data into 75% used for validation and 25% used for testing\n","# We do not need to shuffle the data, as we are processing every validation / test image exactly once\n","length75Percent = int(0.75 * len(gtsrbTestSet))\n","length25Percent = len(gtsrbTestSet) - length75Percent\n","lengths = [length75Percent, length25Percent]\n","valSet, testSet = torch.utils.data.random_split(gtsrbTestSet, lengths)\n","valLoader = torch.utils.data.DataLoader(valSet, batch_size=batchSize,\n","                                        shuffle=False, pin_memory=True, num_workers=2)\n","numValSamples = len(valSet)\n","\n","testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize,\n","                                         shuffle=False, pin_memory=True, num_workers=2)\n","numTestSamples = len(testSet)\n","\n","# Available traffic sign classes in the dataset\n","classes = [\n","    \"Speed limit (20km/h)\",\n","    \"Speed limit (30km/h)\",\n","    \"Speed limit (50km/h)\",\n","    \"Speed limit (60km/h)\",\n","    \"Speed limit (70km/h)\",\n","    \"Speed limit (80km/h)\",\n","    \"End of speed limit (80km/h)\",\n","    \"Speed limit (100km/h)\",\n","    \"Speed limit (120km/h)\",\n","    \"No passing\",\n","    \"No passing for vehicles over 3.5 metric tons\",\n","    \"Right-of-way at the next intersection\",\n","    \"Priority road\",\n","    \"Yield\",\n","    \"Stop\",\n","    \"No vehicles\",\n","    \"Vehicles over 3.5 metric tons prohibited\",\n","    \"No entry\",\n","    \"General caution\",\n","    \"Dangerous curve to the left\",\n","    \"Dangerous curve to the right\",\n","    \"Double curve\",\n","    \"Bumpy road\",\n","    \"Slippery road\",\n","    \"Road narrows on the right\",\n","    \"Road work\",\n","    \"Traffic signals\",\n","    \"Pedestrians\",\n","    \"Children crossing\",\n","    \"Bicycles crossing\",\n","    \"Beware of ice/snow\",\n","    \"Wild animals crossing\",\n","    \"End of all speed and passing limits\",\n","    \"Turn right ahead\",\n","    \"Turn left ahead\",\n","    \"Ahead only\",\n","    \"Go straight or right\",\n","    \"Go straight or left\",\n","    \"Keep right\",\n","    \"Keep left\",\n","    \"Roundabout mandatory\",\n","    \"End of no passing\",\n","    \"End of no passing by vehicles over 3.5 metric tons\",\n","]\n","\n","numClasses = len(classes)"]},{"cell_type":"markdown","metadata":{"id":"87UhB27vHF-2"},"source":["### Print dataset statistics (**PROVIDED**)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phTyA38CrN4R"},"outputs":[],"source":["print(\"Dataset Statistics\")\n","print(f\"  # of training samples:   {numTrainSamples}\")\n","print(f\"  # of validation samples: {numValSamples}\")\n","print(f\"  # of test samples:       {numTestSamples}\")\n","print(f\"  # of different classes:  {numClasses}\")"]},{"cell_type":"markdown","metadata":{"id":"bfjD8gP3HOCC"},"source":["### Visualize the data (**PROVIDED**)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wzSin5MirN4R"},"outputs":[],"source":["# Visualize a random batch of data from the data set\n","\n","def imshow(img):\n","    npimg = img.cpu().numpy() # make sure image is in host memory\n","\n","    # normalize to 0-1 for visualization\n","    minPixel = np.min(npimg)\n","    maxPixel = np.max(npimg)\n","    npimg = npimg - minPixel\n","    npimg = npimg / (maxPixel-minPixel)\n","\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","\n","numRows = 8\n","\n","# get a single random batch of training images\n","dataIter = iter(trainLoader)\n","images, labels = next(dataIter)\n","\n","# print labels\n","for i in range( batchSize // numRows ):\n","    print('\\n'.join(f'Image {j:2d}: {classes[labels[j]]:5s}' for j in range((i*numRows), (i*numRows)+numRows)))\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images, nrow=numRows))"]},{"cell_type":"markdown","metadata":{"id":"ATTSTJH6P8ZX"},"source":["### Neural Network Model Definition (**add your code here**)\n","\n","We want to design a standard \"feed-forward\" multilayer perceptron as seen in the [tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html). In PyTorch terms, this is a Python class that subclasses [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) and contains `__init__()` and `forward()`. Note that you do not have to use `nn.Sequential` as seen in the [tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html). This only groups layers together but is not necessary. You can also treat each layer separately, e.g. as shown in this [tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network).\n","\n","\n","We will need the following layers (input to output):\n","\n","* The input will be the raw pixel values, i.e. 12288 values (images of 64x64x3 flattened into a single vector)\n","* 4 [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) layers with 512, 256, 128, 64 neurons each\n","* The output layer is a [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) layer with `numClasses` neurons, one neuron per class\n","* All neurons except for neurons in the output layer should have [`torch.nn.functional.leaky_relu`](https://pytorch.org/docs/stable/generated/torch.nn.functional.leaky_relu.html#torch.nn.functional.leaky_relu) activation functions\n","* **Important: The output layer must not have any activation function. It will be automatically applied in the loss computation (softmax activation for CrossEntropy loss, as seen in the lecture).**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrPJ4BVfQFIV"},"outputs":[],"source":["## Define the layers of the MLP network model\n","\n","###### YOUR CODE GOES HERE ######\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","      self.flatten = nn.Flatten()\n","      self.fc1 = nn.Linear(64*64*3, 512)\n","      self.fc2 = nn.Linear(512, 256)\n","      self.fc3 = nn.Linear(256, 128)\n","      self.fc4 = nn.Linear(128, 64)\n","      self.fc5 = nn.Linear(64, numClasses)\n","\n","    def forward(self, x):\n","      x = self.flatten(x)\n","      x = F.leaky_relu(self.fc1(x))\n","      x = F.leaky_relu(self.fc2(x))\n","      x = F.leaky_relu(self.fc3(x))\n","      x = F.leaky_relu(self.fc4(x))\n","      x = self.fc5(x)\n","      return x\n","#################################\n"]},{"cell_type":"markdown","metadata":{"id":"vRk0xlhSV6FG"},"source":["### Print a summary of the structure of our network using the `torchinfo` package. (**PROVIDED**)\n","\n","The result should look similar to:\n","```\n","==========================================================================================\n","Layer (type (var_name))                  Output Shape              Param #\n","==========================================================================================\n","Net (Net)                                [1, 43]                   --\n","├─Linear (fc1)                           [1, 512]                  6,291,968\n","├─Linear (fc2)                           [1, 256]                  131,328\n","├─Linear (fc3)                           [1, 128]                  32,896\n","├─Linear (fc4)                           [1, 64]                   8,256\n","├─Linear (fc5)                           [1, 43]                   2,795\n","==========================================================================================\n","Total params: 6,467,243\n","Trainable params: 6,467,243\n","Non-trainable params: 0\n","Total mult-adds (M): 6.47\n","==========================================================================================\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 25.87\n","Estimated Total Size (MB): 25.93\n","==========================================================================================\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19K2Ilh2rN4S"},"outputs":[],"source":["# Instatiate our neural network\n","network = Net()\n","\n","# Print a summary of the net\n","%pip install torchinfo\n","\n","from torchinfo import summary\n","summary(network, input_size=(1, 3, 64, 64), row_settings=[\"var_names\"])"]},{"cell_type":"markdown","metadata":{"id":"haklMQnXWTEB"},"source":["### Question\n","\n","Why is the number of learnable parameters of the first hidden layer `6,291,968`?\n","\n","Vollvernetzung -> 12288 (Input) x 512 (Neuronen) = 6,291,456\n","\n","Bias --> 6,291,456 + 512 Bias = 6,291,968"]},{"cell_type":"markdown","metadata":{"id":"UvI94m1V_6gq"},"source":["#### Your Answer:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j5P7r_rHQ9hm"},"source":["### Neural Network Training (**add your code here**)\n","\n","To train our network, we will first have to define a loss function, an optimizer and hyperparameters that control the training process:\n","\n","* [`torch.optim.AdamW`](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html?highlight=adamw#torch.optim.AdamW) is used as an optimizer with default parameters except for the learning rate which is set to `lr=3e-4`.\n","* [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) is used as loss function. Note, that the softmax activation is applied during loss computation, as stated in the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)\n","* The number of training epochs is 15\n","\n","\n","Train your multilayer perceptron network using the `Trainer` class and provide `trainLoader` as the DataLoader for training data and `valLoader` as the DataLoader for validation data.\n","\n","The overall training should take about 20 seconds per epoch (**on a GPU**, depending on what GPU is assigned). Reported accuracies on the training (validation) data should be approx. 95% (81%) after 15 training epochs.   \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsVNpyKvRAUC"},"outputs":[],"source":["##### YOUR CODE GOES HERE ######\n","lr = 3e-4\n","model = network\n","param_optimizer = model.parameters()\n","lossFunction = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(param_optimizer, lr=lr)\n","\n","trainer = Trainer(model, lossFunction, optimizer, device)\n","trainer.train(trainLoader, valLoader, 15)\n","################################"]},{"cell_type":"markdown","metadata":{"id":"Qrwavtq-Re_J"},"source":["### Visualize the behavior of the loss and accuracy (**add your code here**)\n","\n","Using the data available in `trainer.metrics`, create the following two plots:\n","* Training loss and validation loss as a function of epochs.  \n","* Training accuracy and validation accuracy as a function of epochs.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsa77qfRRrDv"},"outputs":[],"source":["##### YOUR CODE GOES HERE ######\n","trainLoss = trainer.metrics[\"epochTrainLoss\"]\n","valLoss = trainer.metrics[\"epochValLoss\"]\n","trainacc = trainer.metrics[\"epochTrainAccuracy\"]\n","trainValacc = trainer.metrics[\"epochValAccuracy\"]\n","\n","# Number of epochs\n","epochs = range(1, len(trainLoss) + 1)\n","\n","# Plotting training and validation loss\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, trainLoss, 'b', label='Training loss')\n","plt.plot(epochs, valLoss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plotting training and validation accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, trainacc, 'b', label='Training accuracy')\n","plt.plot(epochs, trainValacc, 'r', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","################################"]},{"cell_type":"markdown","metadata":{"id":"ZzhYCKJYTiIb"},"source":["### Run your network on some images to get predictions (**PROVIDED**)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILGixiytTo2A"},"outputs":[],"source":["# Run some batches of unseen test data through the network and visualize its predictions\n","numBatches = 4\n","numRows = 8\n","\n"," # Iterator through the test DataLoader\n","dataIter = iter(testLoader)\n","\n","# for each batch\n","for batch in range(numBatches):\n","\n","    # get images and ground truth labels\n","    images, labels = next(dataIter)\n","\n","    # push to the device used\n","    images, labels = images.to(device), labels.to(device)\n","\n","    # forward pass of the batch of images\n","    outputs = network(images)\n","\n","    # find the index of the class with the largest output\n","    _, predictedLabels         = torch.max(outputs, 1)\n","\n","    # print labels and outputs\n","    countCorrect = 0\n","    for i in range( batchSize // numRows ):\n","        for j in range((i*numRows), (i*numRows)+numRows):\n","            print(f'Image {j:2d} - Label: {classes[labels[j]]:5s} | Prediction: {classes[predictedLabels[j]]:5s}')\n","            if labels[j] == predictedLabels[j]:\n","                countCorrect = countCorrect + 1\n","\n","    print(f\"\\n{(countCorrect / batchSize) * 100.0:.2f}% of test images correctly classified\")\n","\n","    # show images\n","    imshow(torchvision.utils.make_grid(images))"]},{"cell_type":"markdown","metadata":{"id":"P4W79bpYY1BO"},"source":["### Evaluate the performance on the unseen test data set.  (**add your code here**)\n","\n","Use the proviced `Tester` class (see above) and test your trained network on the unseen test set available via `testLoader`. Your trained network should have approximately 80% accuracy (+- 2% depending on randomness during training)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DSjVLeXIrN4U"},"outputs":[],"source":["###### YOUR CODE GOES HERE ######\n","# Test the network on the final test set\n","\n","# Test a neural network model\n","# create a tester\n","tester = Tester(model, device)\n","# test the model\n","tester.test(testLoader)\n","\n","#################################"]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"mlx-pytorch-2024-01","language":"python","name":"mlx-pytorch-2024-01"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"vscode":{"interpreter":{"hash":"be0721c968e9e259b6060574977180c78678bb42c4e1b679bdf73858ca605d14"}}},"nbformat":4,"nbformat_minor":0}